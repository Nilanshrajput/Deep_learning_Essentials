{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commenly_used_code_snippets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jRLZDz7wTbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCkQdX0TwVPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3X1bjTlwaIg",
        "colab_type": "text"
      },
      "source": [
        "###\n",
        "\n",
        "Connecting to drive\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHa-090-wVUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQTaYfA4wWwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4E0FeoAwHSg",
        "colab_type": "text"
      },
      "source": [
        "###\n",
        "###   DOWLOAD IMAGE OR ANY FILE\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJj2QQyvvp0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "import matplotlib\n",
        "file_name = 'out2.png'\n",
        "matplotlib.image.imsave(file_name, img)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAIwBF5iE1xf",
        "colab_type": "text"
      },
      "source": [
        "###\n",
        "\n",
        "Tensorflow image loading,resizing, preprocessing functions\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGkbCl6xwGpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "keras = tf.keras\n",
        "\n",
        "#Takes path to file as input\n",
        "def load(image_file):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "\n",
        "  w = tf.shape(image)[1]\n",
        "\n",
        "  w = w // 2\n",
        "  input_image = image[:, w:, :]\n",
        "\n",
        "  input_image = tf.cast(input_image, tf.float32)  \n",
        "  return input_image\n",
        "\n",
        "\n",
        "def resize(input_image, height, width):\n",
        "    input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return input_image\n",
        "\n",
        "# normalizing the images to [-1, 1]\n",
        "\n",
        "def normalize(input_image):\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    return input_image\n",
        "\n",
        "def preprocess_imgs(input_image):\n",
        "    size=256\n",
        "    input_image=resize(input,size,size)\n",
        "    input_image = np.expand_dims(input_image, axis=0)\n",
        "    \n",
        "    ###\n",
        "    #Not using normalize function as it is done internanlly the step below\n",
        "    ###\n",
        "    \n",
        "    input_image = keras.applications.ResNet50.preprocess_inputpreprocess_input(x)\n",
        "\n",
        "    return input_image\n",
        "  \n",
        "\"\"\"\n",
        "\n",
        "####\n",
        "Various models present in tf2.0\n",
        "####\n",
        "\n",
        "DenseNet121(...): Instantiates the DenseNet architecture.\n",
        "\n",
        "DenseNet169(...): Instantiates the DenseNet architecture.\n",
        "\n",
        "DenseNet201(...): Instantiates the DenseNet architecture.\n",
        "\n",
        "InceptionResNetV2(...): Instantiates the Inception-ResNet v2 architecture.\n",
        "\n",
        "InceptionV3(...): Instantiates the Inception v3 architecture.\n",
        "\n",
        "MobileNet(...): Instantiates the MobileNet architecture.\n",
        "\n",
        "NASNetLarge(...): Instantiates a NASNet model in ImageNet mode.\n",
        "\n",
        "NASNetMobile(...): Instantiates a Mobile NASNet model in ImageNet mode.\n",
        "\n",
        "ResNet50(...): Instantiates the ResNet50 architecture.\n",
        "\n",
        "VGG16(...): Instantiates the VGG16 architecture.\n",
        "\n",
        "VGG19(...): Instantiates the VGG19 architecture.\n",
        "\n",
        "Xception(...): Instantiates the Xception architecture.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb8pbpkzCNRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from albumentations import (\n",
        "    PadIfNeeded,\n",
        "    HorizontalFlip,\n",
        "    VerticalFlip,    \n",
        "    CenterCrop,    \n",
        "    Crop,\n",
        "    Compose,\n",
        "    Transpose,\n",
        "    RandomRotate90,\n",
        "    ElasticTransform,\n",
        "    GridDistortion, \n",
        "    OpticalDistortion,\n",
        "    RandomSizedCrop,\n",
        "    OneOf,\n",
        "    CLAHE,\n",
        "    RandomBrightnessContrast,    \n",
        "    RandomGamma,\n",
        "    RGBShift\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClaqDooMCSLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_height=224\n",
        "original_width=224\n",
        "aug = Compose([\n",
        "    OneOf([RandomSizedCrop(min_max_height=(50, 101), height=original_height, width=original_width, p=0.5),\n",
        "          PadIfNeeded(min_height=original_height, min_width=original_width, p=0.5)], p=1),    \n",
        "    VerticalFlip(p=0.5),              \n",
        "    RandomRotate90(p=0.5),\n",
        "    OneOf([\n",
        "        ElasticTransform(p=0.4, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        GridDistortion(p=0.3),\n",
        "        OpticalDistortion(p=0.4, distort_limit=2, shift_limit=0.5)                  \n",
        "        ], p=0.8),\n",
        "    CLAHE(p=0.8),\n",
        "    RandomBrightnessContrast(p=0.8),\n",
        "    RGBShift(r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, always_apply=False, p=0.9),\n",
        "    RandomGamma(p=0.8)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x7zDnsTCeFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualize(image, mask, original_image=None, original_mask=None):\n",
        "    fontsize = 18\n",
        "    \n",
        "    if original_image is None and original_mask is None:\n",
        "        f, ax = plt.subplots(2, 1, figsize=(8, 8))\n",
        "\n",
        "        ax[0].imshow(image)\n",
        "        ax[1].imshow(mask)\n",
        "    else:\n",
        "        f, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
        "\n",
        "        ax[0, 0].imshow(original_image)\n",
        "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
        "        \n",
        "        ax[1, 0].imshow(original_mask)\n",
        "        ax[1, 0].set_title('Original mask', fontsize=fontsize)\n",
        "        \n",
        "        ax[0, 1].imshow(image)\n",
        "        ax[0, 1].set_title('Transformed image', fontsize=fontsize)\n",
        "        \n",
        "        ax[1, 1].imshow(mask)\n",
        "        ax[1, 1].set_title('Transformed mask', fontsize=fontsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7Lrybz4CxC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented = aug(image=image, mask=mask)\n",
        "\n",
        "image_elastic = augmented['image']\n",
        "mask_elastic = augmented['mask']\n",
        "\n",
        "visualize(image_elastic, mask_elastic, original_image=image, original_mask=mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejaeI7ecBu3_",
        "colab_type": "text"
      },
      "source": [
        "Batch Generator, using above preprocessing functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwPYhiGtwUSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_generator(input_ids, batch_size = 32,is_training=0):\n",
        "  \n",
        "  while True:\n",
        "    batch_paths = np.random.choice(a= input_ids, size = batch_size)\n",
        "    \n",
        "    batch_input = []\n",
        "    batch_output = []\n",
        "    \n",
        "    for input_id in batch_paths:\n",
        "      output = cv2.imread(join(path_gt, input_id+'-gt.pbm'))\n",
        "      input = cv2.imread(join(path_org, input_id+'-org.jpg'))\n",
        "      \n",
        "      input = preprocess_image(input) \n",
        "      output = preprocess_image(output) \n",
        "      if is_training:\n",
        "        augmented = aug(image=input, mask=output)\n",
        "        input=augmented['image']\n",
        "        output=augmented['mask']\n",
        "\n",
        "      \n",
        "      batch_input += [input]\n",
        "      batch_output += [output]\n",
        "   \n",
        "    batch_x = np.array(batch_input)\n",
        "    batch_y = np.array(batch_output)\n",
        "    \n",
        "    \n",
        "    \n",
        "    yield (batch_x, batch_y)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXfiDRb7CSgr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}