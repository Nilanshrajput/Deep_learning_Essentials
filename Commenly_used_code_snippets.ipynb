{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commenly_used_code_snippets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nilanshrajput/Deep_learning_Essentials/blob/master/Commenly_used_code_snippets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jRLZDz7wTbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCkQdX0TwVPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3X1bjTlwaIg",
        "colab_type": "text"
      },
      "source": [
        "###\n",
        "\n",
        "Connecting to drive\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHa-090-wVUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQTaYfA4wWwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4E0FeoAwHSg",
        "colab_type": "text"
      },
      "source": [
        "###\n",
        "###   DOWLOAD IMAGE OR ANY FILE\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJj2QQyvvp0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "import matplotlib\n",
        "file_name = 'out2.png'\n",
        "matplotlib.image.imsave(file_name, img)\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAIwBF5iE1xf",
        "colab_type": "text"
      },
      "source": [
        "###\n",
        "\n",
        "Tensorflow image loading,resizing, preprocessing functions\n",
        "\n",
        "###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGkbCl6xwGpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "keras = tf.keras\n",
        "\n",
        "#Takes path to file as input\n",
        "def load(image_file):\n",
        "  image = tf.io.read_file(image_file)\n",
        "  image = tf.image.decode_jpeg(image)\n",
        "\n",
        "  w = tf.shape(image)[1]\n",
        "\n",
        "  w = w // 2\n",
        "  input_image = image[:, w:, :]\n",
        "\n",
        "  input_image = tf.cast(input_image, tf.float32)  \n",
        "  return input_image\n",
        "\n",
        "\n",
        "def resize(input_image, height, width):\n",
        "    input_image = tf.image.resize(input_image, [height, width],\n",
        "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return input_image\n",
        "\n",
        "# normalizing the images to [-1, 1]\n",
        "\n",
        "def normalize(input_image):\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    return input_image\n",
        "\n",
        "def preprocess_imgs(input_image):\n",
        "    size=256\n",
        "    input_image=resize(input,size,size)\n",
        "    input_image = np.expand_dims(input_image, axis=0)\n",
        "    \n",
        "    ###\n",
        "    #Not using normalize function as it is done internanlly the step below\n",
        "    ###\n",
        "    \n",
        "    input_image = keras.applications.ResNet50.preprocess_inputpreprocess_input(x)\n",
        "\n",
        "    return input_image\n",
        "  \n",
        "\"\"\"\n",
        "\n",
        "####\n",
        "Various models present in tf2.0\n",
        "####\n",
        "\n",
        "DenseNet121(...): Instantiates the DenseNet architecture.\n",
        "\n",
        "DenseNet169(...): Instantiates the DenseNet architecture.\n",
        "\n",
        "DenseNet201(...): Instantiates the DenseNet architecture.\n",
        "\n",
        "InceptionResNetV2(...): Instantiates the Inception-ResNet v2 architecture.\n",
        "\n",
        "InceptionV3(...): Instantiates the Inception v3 architecture.\n",
        "\n",
        "MobileNet(...): Instantiates the MobileNet architecture.\n",
        "\n",
        "NASNetLarge(...): Instantiates a NASNet model in ImageNet mode.\n",
        "\n",
        "NASNetMobile(...): Instantiates a Mobile NASNet model in ImageNet mode.\n",
        "\n",
        "ResNet50(...): Instantiates the ResNet50 architecture.\n",
        "\n",
        "VGG16(...): Instantiates the VGG16 architecture.\n",
        "\n",
        "VGG19(...): Instantiates the VGG19 architecture.\n",
        "\n",
        "Xception(...): Instantiates the Xception architecture.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejaeI7ecBu3_",
        "colab_type": "text"
      },
      "source": [
        "Batch Generator, using above preprocessing functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwPYhiGtwUSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_generator(input_ids, batch_size = 32,is_training=0):\n",
        "  \n",
        "  while True:\n",
        "    batch_paths = np.random.choice(a= input_ids, size = batch_size)\n",
        "    \n",
        "    batch_input = []\n",
        "    batch_output = []\n",
        "    \n",
        "    for input_id in batch_paths:\n",
        "      output = cv2.imread(join(path_gt, input_id+'-gt.pbm'))\n",
        "      input = cv2.imread(join(path_org, input_id+'-org.jpg'))\n",
        "      \n",
        "      input = preprocess_image(input) \n",
        "      output = preprocess_image(output) \n",
        "      if is_training:\n",
        "        augmented = aug(image=input, mask=output)\n",
        "        input=augmented['image']\n",
        "        output=augmented['mask']\n",
        "\n",
        "      \n",
        "      batch_input += [input]\n",
        "      batch_output += [output]\n",
        "   \n",
        "    batch_x = np.array(batch_input)\n",
        "    batch_y = np.array(batch_output)\n",
        "    \n",
        "    \n",
        "    \n",
        "    yield (batch_x, batch_y)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}